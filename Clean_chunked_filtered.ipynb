{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh3qIwsu+7I0650rxIuciG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maianhtran2005/Project_AI/blob/main/Clean_chunked_filtered.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lấy dữ liệu"
      ],
      "metadata": {
        "id": "Ta-LrcWa8Hoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AI/data_cleaned.csv\", nrows=3)\n",
        "df.head(10)\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr-XWZmN9Vx3",
        "outputId": "dbf81f19-b6b2-4eaa-bc14-2450a51843ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['input', 'output', 'sentences', 'input_sentences', 'ratio'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Làm sạch"
      ],
      "metadata": {
        "id": "aQg-uCbv8OVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# === Đọc dữ liệu ===\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AI/data_cleaned.csv\")\n",
        "\n",
        "# === Đọc danh sách từ dừng ===\n",
        "with open(\"/content/drive/My Drive/AI/vietnamese-stopwords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    stopwords = set(w.strip() for w in f if w.strip())\n",
        "\n",
        "# === Hàm làm sạch ngôn ngữ báo chí ===\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    # 1. Loại bỏ HTML tags\n",
        "    soup = BeautifulSoup(str(text), \"lxml\")\n",
        "    for t in soup([\"script\", \"style\", \"noscript\", \"iframe\", \"footer\", \"header\", \"nav\"]):\n",
        "        t.decompose()\n",
        "    text = soup.get_text(separator=\" \")\n",
        "\n",
        "    # 2. Xóa các dòng kiểu \"Theo\", \"Nguồn\", \"Ảnh\", \"Video\"\n",
        "    text = re.sub(r\"(?im)\\b(nguồn|theo|tác giả|tin liên quan|ảnh|video|đọc thêm|bài liên quan)\\b.*\", \"\", text)\n",
        "\n",
        "    # 3. Xóa URL, email, số điện thoại\n",
        "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\b[\\w.+-]+@[\\w.-]+\\.\\w+\\b\", \"\", text)\n",
        "    text = re.sub(r\"\\+?\\d{2,4}[-.\\s]?\\d{3,}([-.\\s]?\\d+)*\", \"\", text)\n",
        "\n",
        "    # 4. Chuẩn hóa khoảng trắng, ký tự đặc biệt\n",
        "    text = re.sub(r\"[^0-9A-Za-zÀ-ỹ.,?!:;\\\"'()\\-\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# === Hàm loại bỏ từ dừng ===\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered = [w for w in words if w.lower() not in stopwords]\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "# === Áp dụng làm sạch trên cột input ===\n",
        "df[\"input_cleaned\"] = df[\"input\"].apply(clean_text)\n",
        "\n",
        "# Giữ lại các cột quan trọng\n",
        "df_cleaned = df[[\"input_cleaned\", \"output\", \"ratio\"]]\n",
        "\n",
        "# === Lưu lại ===\n",
        "output_path = \"/content/drive/My Drive/AI/data_cleaned_processed.csv\"\n",
        "df_cleaned.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
        "print(f\" File kết quả: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDnp4C8u9WMy",
        "outputId": "ad32a1c1-70a9-40fa-ae4a-99f41bfeaf3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " File kết quả: /content/drive/My Drive/AI/data_cleaned_processed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chuyển hóa sang Unicode"
      ],
      "metadata": {
        "id": "EamU2Big8Qo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MNd6Pv79XeU",
        "outputId": "b921b772-fcb9-4812-dc9d-72403a08a7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-8.3.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.12/dist-packages (from underthesea) (8.3.0)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: nltk>=3.8 in /usr/local/lib/python3.12/dist-packages (from underthesea) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from underthesea) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from underthesea) (2.32.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.6.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from underthesea) (6.0.3)\n",
            "Collecting underthesea_core==1.0.5 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.5-cp312-cp312-manylinux2010_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from underthesea) (0.35.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8->underthesea) (2024.11.6)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (2025.8.3)\n",
            "Downloading underthesea-8.3.0-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading underthesea_core-1.0.5-cp312-cp312-manylinux2010_x86_64.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.4/978.4 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: underthesea_core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.11 underthesea-8.3.0 underthesea_core-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import unicodedata\n",
        "import re\n",
        "from underthesea import sent_tokenize\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Đọc file đã làm sạch ===\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AI/data_cleaned_processed.csv\")\n",
        "\n",
        "# === Hàm chuẩn hóa Unicode ===\n",
        "def normalize_and_fix_spacing(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = unicodedata.normalize(\"NFC\", str(text))\n",
        "    # thêm khoảng trắng sau dấu chấm, chấm hỏi, chấm than nếu dính chữ\n",
        "    text = re.sub(r\"([.!?])(?=[^\\s])\", r\"\\1 \", text)\n",
        "    # bỏ khoảng trắng thừa\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "# === Hàm tách câu ===\n",
        "def sentence_split(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    return \" \".join(sentences)  # nối lại bằng khoảng trắng để vẫn 1 dòng\n",
        "\n",
        "# === Áp dụng trên cột input_cleaned và output ===\n",
        "tqdm.pandas()\n",
        "df[\"input_cleaned\"] = df[\"input_cleaned\"].progress_apply(normalize_and_fix_spacing).progress_apply(sentence_split)\n",
        "df[\"output\"] = df[\"output\"].progress_apply(normalize_and_fix_spacing).progress_apply(sentence_split)\n",
        "\n",
        "# === Lưu lại ===\n",
        "output_path = \"/content/drive/My Drive/AI/data_cleaned_final.csv\"\n",
        "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"File kết quả: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nx6xyEM9q8X",
        "outputId": "8d8aa0dc-a5b0-4d96-d847-6da75060eaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42833/42833 [00:04<00:00, 9512.86it/s]\n",
            "100%|██████████| 42833/42833 [00:08<00:00, 4832.91it/s]\n",
            "100%|██████████| 42833/42833 [00:12<00:00, 3343.76it/s]\n",
            "100%|██████████| 42833/42833 [00:21<00:00, 2022.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File kết quả: /content/drive/My Drive/AI/data_cleaned_final.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chuyển đổi sang file jsonl để train"
      ],
      "metadata": {
        "id": "MksHSejU8VZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Đọc dữ liệu ===\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AI/data_cleaned_final.csv\")\n",
        "df = df[(df[\"input_cleaned\"].str.len() > 30) & (df[\"output\"].str.len() > 10)]\n",
        "\n",
        "# === Xử lý giá trị thiếu ===\n",
        "df = df.fillna({\"input_cleaned\": \"\", \"output\": \"\"})\n",
        "\n",
        "# === Hàm chuyển 1 dòng sang JSONL ===\n",
        "def make_record(row):\n",
        "    prompt = str(row[\"input_cleaned\"]).strip()\n",
        "    completion = str(row[\"output\"]).strip()\n",
        "    return {\"prompt\": prompt, \"completion\": \" \" + completion}\n",
        "\n",
        "# === Ghi ra file JSONL ===\n",
        "with open(\"/content/drive/My Drive/AI/train_data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        record = make_record(row)\n",
        "        json.dump(record, f, ensure_ascii=False)\n",
        "        f.write(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnm9KzyR9YAJ",
        "outputId": "076cde50-da77-4141-f2a4-bdb6a50d54bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38302/38302 [00:13<00:00, 2879.88it/s]\n"
          ]
        }
      ]
    }
  ]
}