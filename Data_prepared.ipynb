{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1sa0B9zBfUa-_bxIwW1jaic64bC_6X-Pf",
      "authorship_tag": "ABX9TyNfx81/uyzKMDBGj88Re/ub",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maianhtran2005/Project_AI/blob/main/Data_prepared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlPGGlZwcUH9",
        "outputId": "c415be6e-ffa1-4efd-9986-58cd30339891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Đang đọc dữ liệu từ file: /content/drive/MyDrive/train-00000-of-00002.parquet\n",
            "Đang đọc dữ liệu từ file: /content/drive/MyDrive/train-00000-of-00002.parquet\n",
            "Đã lấy 2500 bản ghi từ file thứ nhất và 2500 bản ghi từ file thứ hai.\n",
            "\n",
            "Thông tin của DataFrame đã gộp:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   report   5000 non-null   object\n",
            " 1   summary  5000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 78.3+ KB\n",
            "\n",
            "Đang ghi 5000 bản ghi vào file: /content/drive/MyDrive/train.parquet\n",
            "\n",
            "✅ Đã hoàn thành! Dữ liệu đã được gộp và lưu vào file '/content/drive/MyDrive/train.parquet'.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Chạy cell này để cài đặt pandas và pyarrow.\n",
        "# Thư viện này giúp xử lý dữ liệu dạng bảng và đọc/ghi file Parquet.\n",
        "\n",
        "!pip install pandas pyarrow\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Thay đổi tên file của bạn tại đây\n",
        "file1_path = '/content/drive/MyDrive/train-00000-of-00002.parquet'\n",
        "file2_path = '/content/drive/MyDrive/train-00000-of-00002.parquet'\n",
        "output_file_path = '/content/drive/MyDrive/train.parquet'\n",
        "\n",
        "# Kiểm tra xem file có tồn tại không trước khi đọc\n",
        "if not os.path.exists(file1_path) or not os.path.exists(file2_path):\n",
        "    print(\"Lỗi: Một hoặc cả hai file parquet không tồn tại. Vui lòng kiểm tra lại đường dẫn.\")\n",
        "else:\n",
        "    # Đọc dữ liệu từ file Parquet\n",
        "    print(f\"Đang đọc dữ liệu từ file: {file1_path}\")\n",
        "    df1 = pd.read_parquet(file1_path)\n",
        "\n",
        "    print(f\"Đang đọc dữ liệu từ file: {file2_path}\")\n",
        "    df2 = pd.read_parquet(file2_path)\n",
        "\n",
        "    # Lấy 2500 bản ghi từ mỗi DataFrame\n",
        "    num_records = 2500\n",
        "    df1_subset = df1.sample(num_records)\n",
        "    df2_subset = df2.sample(num_records)\n",
        "\n",
        "    print(f\"Đã lấy {len(df1_subset)} bản ghi từ file thứ nhất và {len(df2_subset)} bản ghi từ file thứ hai.\")\n",
        "\n",
        "    # Gộp 2 DataFrame thành một\n",
        "    combined_df = pd.concat([df1_subset, df2_subset], ignore_index=True)\n",
        "\n",
        "    # In ra thông tin tóm tắt của DataFrame đã gộp\n",
        "    print(\"\\nThông tin của DataFrame đã gộp:\")\n",
        "    combined_df.info()\n",
        "\n",
        "    # Ghi DataFrame đã gộp ra một file Parquet mới\n",
        "    print(f\"\\nĐang ghi {len(combined_df)} bản ghi vào file: {output_file_path}\")\n",
        "    combined_df.to_parquet(output_file_path, index=False)\n",
        "\n",
        "    print(f\"\\n✅ Đã hoàn thành! Dữ liệu đã được gộp và lưu vào file '{output_file_path}'.\")"
      ]
    }
  ]
}